{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e74ec7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: torch==2.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch==2.9.0->torchvision) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torchvision\n",
    "!pip install tqdm\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0642bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "\n",
    "DEVICE = \"cpu\"     # CPU-only as requested\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "# Federated settings\n",
    "NUM_CLIENTS = 10\n",
    "ROUNDS = 5\n",
    "LOCAL_EPOCHS = 1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Prompt settings\n",
    "PROMPT_LEN = 16\n",
    "EMBED_DIM = 512       # HF CLIP ViT-B/16 text dim\n",
    "\n",
    "# Simulated DP noise (fast)\n",
    "SIGMA_L = 0.3\n",
    "SIGMA_G = 0.1\n",
    "\n",
    "# Low-rank factorization\n",
    "RANK = 4\n",
    "LR_LOCAL = 1e-3\n",
    "LR_GLOBAL = 1e-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a39ee7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c86ba0076854a22b7d9e9d8ead9ea82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e006efd70e854bfb92eea481b89b5694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/599M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:629\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    627\u001b[0m     progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n\u001b[0;32m--> 629\u001b[0m download_files(\n\u001b[1;32m    630\u001b[0m     xet_download_info,\n\u001b[1;32m    631\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mconnection_info\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m    632\u001b[0m     token_info\u001b[38;5;241m=\u001b[39m(connection_info\u001b[38;5;241m.\u001b[39maccess_token, connection_info\u001b[38;5;241m.\u001b[39mexpiration_unix_epoch),\n\u001b[1;32m    633\u001b[0m     token_refresher\u001b[38;5;241m=\u001b[39mtoken_refresher,\n\u001b[1;32m    634\u001b[0m     progress_updater\u001b[38;5;241m=\u001b[39m[progress_updater],\n\u001b[1;32m    635\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_clip \u001b[38;5;241m=\u001b[39m CLIPModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-base-patch16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m processor \u001b[38;5;241m=\u001b[39m CLIPProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/clip-vit-base-patch16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m hf_clip\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_utils.py:288\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_utils.py:5027\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   5017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5018\u001b[0m     gguf_file\n\u001b[1;32m   5019\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5020\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   5021\u001b[0m ):\n\u001b[1;32m   5022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   5023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5025\u001b[0m     )\n\u001b[0;32m-> 5027\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m _get_resolved_checkpoint_files(\n\u001b[1;32m   5028\u001b[0m     pretrained_model_name_or_path\u001b[38;5;241m=\u001b[39mpretrained_model_name_or_path,\n\u001b[1;32m   5029\u001b[0m     subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[1;32m   5030\u001b[0m     variant\u001b[38;5;241m=\u001b[39mvariant,\n\u001b[1;32m   5031\u001b[0m     gguf_file\u001b[38;5;241m=\u001b[39mgguf_file,\n\u001b[1;32m   5032\u001b[0m     from_tf\u001b[38;5;241m=\u001b[39mfrom_tf,\n\u001b[1;32m   5033\u001b[0m     from_flax\u001b[38;5;241m=\u001b[39mfrom_flax,\n\u001b[1;32m   5034\u001b[0m     use_safetensors\u001b[38;5;241m=\u001b[39muse_safetensors,\n\u001b[1;32m   5035\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   5036\u001b[0m     force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   5037\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   5038\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   5039\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   5040\u001b[0m     user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m   5041\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   5042\u001b[0m     commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[1;32m   5043\u001b[0m     is_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_auto_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5044\u001b[0m     transformers_explicit_filename\u001b[38;5;241m=\u001b[39mtransformers_explicit_filename,\n\u001b[1;32m   5045\u001b[0m )\n\u001b[1;32m   5047\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5048\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/modeling_utils.py:1179\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m         filename \u001b[38;5;241m=\u001b[39m _add_variant(WEIGHTS_NAME, variant)\n\u001b[0;32m-> 1179\u001b[0m         resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1180\u001b[0m             pretrained_model_name_or_path, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[1;32m   1181\u001b[0m         )\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   1185\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   1186\u001b[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs,\n\u001b[1;32m   1188\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/hub.py:321\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    264\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    265\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    267\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    322\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/transformers/utils/hub.py:478\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m         hf_hub_download(\n\u001b[1;32m    479\u001b[0m             path_or_repo_id,\n\u001b[1;32m    480\u001b[0m             filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    481\u001b[0m             subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    482\u001b[0m             repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    483\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    484\u001b[0m             cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    485\u001b[0m             user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    486\u001b[0m             force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    487\u001b[0m             proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    488\u001b[0m             resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    489\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    490\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    491\u001b[0m         )\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    493\u001b[0m         snapshot_download(\n\u001b[1;32m    494\u001b[0m             path_or_repo_id,\n\u001b[1;32m    495\u001b[0m             allow_patterns\u001b[38;5;241m=\u001b[39mfull_filenames,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    505\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m   1013\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   1015\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1016\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   1017\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[1;32m   1020\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[1;32m   1021\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[1;32m   1022\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1023\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1026\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1027\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1171\u001b[0m     _download_to_tmp_and_move(\n\u001b[1;32m   1172\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mPath(blob_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.incomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1173\u001b[0m         destination_path\u001b[38;5;241m=\u001b[39mPath(blob_path),\n\u001b[1;32m   1174\u001b[0m         url_to_download\u001b[38;5;241m=\u001b[39murl_to_download,\n\u001b[1;32m   1175\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m   1176\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1177\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1178\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1179\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m   1180\u001b[0m         etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[1;32m   1181\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[1;32m   1182\u001b[0m     )\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:1723\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_xet_available():\n\u001b[1;32m   1722\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo. Downloading file from Xet Storage..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1723\u001b[0m     xet_get(\n\u001b[1;32m   1724\u001b[0m         incomplete_path\u001b[38;5;241m=\u001b[39mincomplete_path,\n\u001b[1;32m   1725\u001b[0m         xet_file_data\u001b[38;5;241m=\u001b[39mxet_file_data,\n\u001b[1;32m   1726\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m   1727\u001b[0m         expected_size\u001b[38;5;241m=\u001b[39mexpected_size,\n\u001b[1;32m   1728\u001b[0m         displayed_filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   1729\u001b[0m     )\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/huggingface_hub/file_download.py:624\u001b[0m, in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    613\u001b[0m     displayed_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplayed_filename[:\u001b[38;5;241m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(â€¦)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    615\u001b[0m progress_cm \u001b[38;5;241m=\u001b[39m _get_progress_bar_context(\n\u001b[1;32m    616\u001b[0m     desc\u001b[38;5;241m=\u001b[39mdisplayed_filename,\n\u001b[1;32m    617\u001b[0m     log_level\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mgetEffectiveLevel(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    621\u001b[0m     _tqdm_bar\u001b[38;5;241m=\u001b[39m_tqdm_bar,\n\u001b[1;32m    622\u001b[0m )\n\u001b[0;32m--> 624\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m progress_cm \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprogress_updater\u001b[39m(progress_bytes: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[1;32m    627\u001b[0m         progress\u001b[38;5;241m.\u001b[39mupdate(progress_bytes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/tqdm/std.py:1138\u001b[0m, in \u001b[0;36mtqdm.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 1138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_value, traceback):\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hf_clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "hf_clip.eval()\n",
    "for p in hf_clip.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "print(\"Loaded HuggingFace CLIP ViT-B/16 (frozen).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\",\n",
    "    split=\"train\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.Flowers102(\n",
    "    root=\"./data\",\n",
    "    split=\"test\",\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "labels = np.array(trainset._labels)\n",
    "print(\"Train samples:\", len(trainset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_by_class = {i: np.where(labels == i)[0] for i in range(102)}\n",
    "\n",
    "classes_per_client = 102 // NUM_CLIENTS\n",
    "client_indices = []\n",
    "\n",
    "start = 0\n",
    "for cid in range(NUM_CLIENTS):\n",
    "    cls_range = list(range(start, start + classes_per_client))\n",
    "    start += classes_per_client\n",
    "\n",
    "    indices = []\n",
    "    for c in cls_range:\n",
    "        indices.extend(idx_by_class[c])\n",
    "\n",
    "    client_indices.append(indices)\n",
    "\n",
    "print(\"Client 0 samples:\", len(client_indices[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684b379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptLearner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_prompt = nn.Parameter(torch.randn(PROMPT_LEN, EMBED_DIM))\n",
    "        self.local_prompt  = nn.Parameter(torch.randn(PROMPT_LEN, EMBED_DIM))\n",
    "\n",
    "    def full_prompt(self):\n",
    "        return self.global_prompt + self.local_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6facf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_rank_factorization(mat, rank=RANK):\n",
    "    Q = torch.randn(mat.size(1), rank)\n",
    "    Q = torch.linalg.qr(Q).Q\n",
    "    Z = mat.T @ (mat @ Q)\n",
    "    Q = torch.linalg.qr(Z).Q\n",
    "\n",
    "    u = mat @ Q\n",
    "    v = Q.T\n",
    "    approx = u @ v\n",
    "    residual = mat - approx\n",
    "    return u, v, residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd65d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, cid, indices, global_model):\n",
    "        self.cid = cid\n",
    "        self.indices = indices\n",
    "        self.model = copy.deepcopy(global_model)\n",
    "\n",
    "    def get_loader(self):\n",
    "        ds = Subset(trainset, self.indices)\n",
    "        return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    def local_train(self):\n",
    "        loader = self.get_loader()\n",
    "        opt = torch.optim.SGD(self.model.parameters(), lr=LR_LOCAL)\n",
    "\n",
    "        losses = []\n",
    "\n",
    "        for _ in range(LOCAL_EPOCHS):\n",
    "            for img, label in loader:\n",
    "                inputs = processor(images=img, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # factorize local prompt\n",
    "                u, v, r = low_rank_factorization(self.model.local_prompt)\n",
    "                p_local = u @ v + r\n",
    "\n",
    "                text_features = hf_clip.text_model(p_local.unsqueeze(0)).last_hidden_state.mean(1)\n",
    "                img_features = hf_clip.vision_model(inputs).pooler_output\n",
    "\n",
    "                logits = (text_features @ img_features.T) / 0.07\n",
    "                loss = F.cross_entropy(logits, label)\n",
    "                loss.backward()\n",
    "\n",
    "                # Simulated LDP noise\n",
    "                for name, p in self.model.named_parameters():\n",
    "                    if \"local\" in name and p.grad is not None:\n",
    "                        p.grad += torch.randn_like(p.grad) * SIGMA_L\n",
    "\n",
    "                opt.step()\n",
    "                losses.append(loss.item())\n",
    "\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def get_global_grad(self):\n",
    "        # simulated GDP noise\n",
    "        grad = torch.randn_like(self.model.global_prompt) * SIGMA_G\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.global_model = PromptLearner()\n",
    "        self.clients = [\n",
    "            Client(cid, client_indices[cid], self.global_model)\n",
    "            for cid in range(NUM_CLIENTS)\n",
    "        ]\n",
    "\n",
    "    def aggregate(self, grads):\n",
    "        mean_grad = torch.stack(grads).mean(dim=0)\n",
    "        noisy_grad = mean_grad + torch.randn_like(mean_grad) * SIGMA_G\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.global_model.global_prompt -= LR_GLOBAL * noisy_grad\n",
    "\n",
    "    def run(self):\n",
    "        for r in range(ROUNDS):\n",
    "            print(f\"\\n=== Round {r+1}/{ROUNDS} ===\")\n",
    "            grads = []\n",
    "            losses = []\n",
    "\n",
    "            for client in tqdm(self.clients):\n",
    "                client.model.global_prompt.data = self.global_model.global_prompt.data.clone()\n",
    "\n",
    "                losses.append(client.local_train())\n",
    "                grads.append(client.get_global_grad())\n",
    "\n",
    "            self.aggregate(grads)\n",
    "            print(\"Avg Loss:\", np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f48b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = Server()\n",
    "server.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_client(client):\n",
    "    client.model.eval()\n",
    "    loader = DataLoader(testset, batch_size=32)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    prompt = client.model.full_prompt()\n",
    "    text_features = hf_clip.text_model(prompt.unsqueeze(0)).last_hidden_state.mean(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in loader:\n",
    "            inputs = processor(images=img, return_tensors=\"pt\")[\"pixel_values\"]\n",
    "            img_features = hf_clip.vision_model(inputs).pooler_output\n",
    "\n",
    "            logits = (text_features @ img_features.T) / 0.07\n",
    "            pred = logits.argmax(dim=0)\n",
    "\n",
    "            correct += (pred == label).sum().item()\n",
    "            total += len(label)\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "for cid, client in enumerate(server.clients):\n",
    "    print(f\"Client {cid} Accuracy:\", evaluate_client(client))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
