{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6a28cdfd4a0e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:12.886140Z",
     "start_time": "2025-11-15T09:44:12.149037Z"
    }
   },
   "outputs": [],
   "source": [
    "## Lightweight PyTorch Implementation of DP-FPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b2c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "\n",
    "# -------------------------------\n",
    "# Hyperparameters\n",
    "# -------------------------------\n",
    "NUM_CLIENTS = 5\n",
    "ROUNDS = 5\n",
    "LOCAL_EPOCHS = 2\n",
    "BATCH_SIZE = 32\n",
    "EMBED_DIM = 128       # prompt dimension\n",
    "PROMPT_LEN = 16\n",
    "RANK = 4\n",
    "LR_GLOBAL = 1e-3\n",
    "LR_LOCAL = 1e-3\n",
    "SIGMA_G = 0.2         # GDP noise std\n",
    "SIGMA_L = 0.4         # LDP noise std\n",
    "C_TH = 1.0            # gradient clipping threshold\n",
    "DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d85d66fe31de38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:15.745441Z",
     "start_time": "2025-11-15T09:44:15.741581Z"
    }
   },
   "outputs": [],
   "source": [
    "class FrozenCLIP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.text_encoder = nn.Linear(EMBED_DIM, EMBED_DIM, bias=False)\n",
    "        self.image_encoder = nn.Linear(EMBED_DIM, EMBED_DIM, bias=False)\n",
    "        # freeze parameters\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, text_prompt, image):\n",
    "        t_feat = F.normalize(self.text_encoder(text_prompt), dim=-1)\n",
    "        i_feat = F.normalize(self.image_encoder(image), dim=-1)\n",
    "        return t_feat, i_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74d2ca271b1881fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:18.685067Z",
     "start_time": "2025-11-15T09:44:18.681455Z"
    }
   },
   "outputs": [],
   "source": [
    "class PromptLearner(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_prompt = nn.Parameter(torch.randn(PROMPT_LEN, EMBED_DIM))\n",
    "        self.local_prompt = nn.Parameter(torch.randn(PROMPT_LEN, EMBED_DIM))\n",
    "\n",
    "    def get_prompt(self):\n",
    "        return self.global_prompt + self.local_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620f1aec6e08ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:21.692372Z",
     "start_time": "2025-11-15T09:44:21.688901Z"
    }
   },
   "outputs": [],
   "source": [
    "def factorize_low_rank(mat, rank=RANK):\n",
    "    \"\"\"Return u, v, residual for matrix mat (PROMPT_LEN x EMBED_DIM).\"\"\"\n",
    "    n = mat.size(1)\n",
    "    q = torch.randn(n, rank)\n",
    "    for _ in range(1):  # one iteration of power method\n",
    "        q = torch.linalg.qr(mat.T @ (mat @ q)).Q\n",
    "    u = mat @ q\n",
    "    v = q.T\n",
    "    approx = u @ v\n",
    "    residual = mat - approx\n",
    "    return u, v, residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3727249a632f4f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:25.464030Z",
     "start_time": "2025-11-15T09:44:25.458371Z"
    }
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, cid, model, data_size=1000):\n",
    "        self.cid = cid\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.clip = FrozenCLIP()\n",
    "        self.data_size = data_size\n",
    "\n",
    "    def local_train(self):\n",
    "        opt = torch.optim.SGD(self.model.parameters(), lr=LR_LOCAL)\n",
    "        for _ in range(LOCAL_EPOCHS):\n",
    "            # Simulate random \"images\" and \"labels\"\n",
    "            x = torch.randn(BATCH_SIZE, EMBED_DIM)\n",
    "            y = torch.randint(0, PROMPT_LEN, (BATCH_SIZE,))\n",
    "\n",
    "            # Factorize local prompt\n",
    "            u, v, r = factorize_low_rank(self.model.local_prompt)\n",
    "            p_local = u @ v + r\n",
    "\n",
    "            # Forward through frozen CLIP\n",
    "            t_feat, i_feat = self.clip(p_local, x)\n",
    "            logits = (i_feat @ t_feat.T) / 0.07\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            # Compute gradients\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip and add LDP noise\n",
    "            for name, p in self.model.named_parameters():\n",
    "                if \"local\" in name and p.grad is not None:\n",
    "                    grad = p.grad\n",
    "                    grad = grad.clamp(-C_TH, C_TH)\n",
    "                    grad += torch.normal(0, SIGMA_L, grad.shape)\n",
    "                    p.data -= LR_LOCAL * grad\n",
    "        return loss.item()\n",
    "\n",
    "    def get_global_grad(self):\n",
    "        # Return noisy gradient for global prompt only\n",
    "        grad = torch.randn_like(self.model.global_prompt)\n",
    "        grad = grad.clamp(-C_TH, C_TH)\n",
    "        grad += torch.normal(0, SIGMA_G, grad.shape)\n",
    "        return grad\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9e3cfc7e9aeec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:33.366441Z",
     "start_time": "2025-11-15T09:44:33.362002Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.global_model = PromptLearner()\n",
    "        self.clients = [Client(i, self.global_model) for i in range(NUM_CLIENTS)]\n",
    "\n",
    "    def aggregate(self, grads):\n",
    "        mean_grad = torch.stack(grads).mean(0)\n",
    "        self.global_model.global_prompt.data -= LR_GLOBAL * mean_grad\n",
    "\n",
    "    def run(self):\n",
    "        for rnd in range(ROUNDS):\n",
    "            grads = []\n",
    "            losses = []\n",
    "            for client in self.clients:\n",
    "                # Broadcast global prompt\n",
    "                client.model.global_prompt.data = self.global_model.global_prompt.data.clone()\n",
    "                loss = client.local_train()\n",
    "                grads.append(client.get_global_grad())\n",
    "                losses.append(loss)\n",
    "            self.aggregate(grads)\n",
    "            print(f\"Round {rnd+1}: mean loss = {sum(losses)/len(losses):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953bc24024d2674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-15T09:44:37.424065Z",
     "start_time": "2025-11-15T09:44:36.645583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1: mean loss = 3.4621\n",
      "Round 2: mean loss = 3.4364\n",
      "Round 3: mean loss = 3.4776\n",
      "Round 4: mean loss = 3.2800\n",
      "Round 5: mean loss = 3.3831\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    server = Server()\n",
    "    server.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1df11649685e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5ee61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
